{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48309564-7ad0-42d8-9d3a-6fc0918d21c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad8ee0ec-eef2-46db-ae6d-8ade7e448834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Read CSV file in Spark - 1. Fisrt uploaded data in table. New -> Table -> Uploaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6072ef93-9445-4f82-9bdb-b0c60f50f7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|              _c0|                _c1|  _c2|\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "            .option(\"inferschema\", \"false\")\\\n",
    "                .option(\"mode\", \"FAILFAST\")\\\n",
    "                    .load(\"/FileStore/tables/flight.csv\")\n",
    "\n",
    "df_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f09027-9a50-4153-a5ff-16ad7d87b4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight_new=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"false\")\\\n",
    "                .option(\"mode\", \"FAILFAST\")\\\n",
    "                    .load(\"/FileStore/tables/flight.csv\")\n",
    "\n",
    "df_flight_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d1ce5e-d3b0-491a-9760-2ce89edf9a43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c39ae69-d873-4a20-8f1d-88c981dd6af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight_new_schema=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                .option(\"mode\", \"FAILFAST\")\\\n",
    "                    .load(\"/FileStore/tables/flight.csv\")\n",
    "\n",
    "df_flight_new_schema.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9428324a-5fbe-40f8-95ee-d87d55873d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight_new_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3961ff9d-cf4e-4bc8-b7f3-1b85542ec5df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Manual Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5ed447-b7ef-4b73-808d-c503f6c8004c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfe608d-46cf-478d-9bc0-5e0618fe4746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_schema=StructType([\n",
    "    StructField(\"DEST_COUNTRY_NAME\",StringType(), True),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\",StringType(), True),\n",
    "    StructField(\"count\",IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1830f24d-4708-47a1-ae42-e1378cd2cffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight_new_schema_new=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "            .option(\"skipRows\",1)\\\n",
    "            .option(\"inferschema\", \"false\")\\\n",
    "                .schema(my_schema)\\\n",
    "                .option(\"mode\", \"PERMISSIVE\")\\\n",
    "                    .load(\"/FileStore/tables/flight.csv\")\n",
    "\n",
    "df_flight_new_schema_new.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aaa0af5-d6a8-427f-a465-72ef80285a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/flight.csv</td><td>flight.csv</td><td>7121</td><td>1736400722000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/flight.csv",
         "flight.csv",
         7121,
         1736400722000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls /FileStore/tables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06b1cba8-7162-4e73-b140-a50c0b585fe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Corrupted Record Handling - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ec6262-8266-4217-8e34-eb595029e4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+-----------------+-------+\n",
      "| id|      name|age|salary|          address|nominee|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "|  1|    Manish| 26| 75000|            Bihar|   nom1|\n",
      "|  2|    Nikita| 27| 45800|               UP|   nom2|\n",
      "|  3|    Pritam| 24| 45720|Bangalore,Kolkata|   nom3|\n",
      "|  4|Prathamesh| 22|789651|    India,Kolkata|   nom4|\n",
      "|  5|      Roni| 21| 30000|             null|   nom5|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                .option(\"mode\", \"PERMISSIVE\")\\\n",
    "                    .load(\"/FileStore/tables/employee-1.csv\")\n",
    "\n",
    "df_employee.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "692dbf91-661d-4e7d-acbd-e28f3beeb55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+-----------------+-------+\n",
      "| id|      name|age|salary|          address|nominee|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "|  1|    Manish| 26| 75000|            Bihar|   nom1|\n",
      "|  2|    Nikita| 27| 45800|               UP|   nom2|\n",
      "|  3|    Pritam| 24| 45720|Bangalore,Kolkata|   nom3|\n",
      "|  4|Prathamesh| 22|789651|    India,Kolkata|   nom4|\n",
      "|  5|      Roni| 21| 30000|             null|   nom5|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "                    .load(\"/FileStore/tables/employee-1.csv\")\n",
    "\n",
    "df_employee.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f294ef-d3f0-4061-9217-2a96ebbf7da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+-----------------+-------+\n",
      "| id|      name|age|salary|          address|nominee|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "|  1|    Manish| 26| 75000|            Bihar|   nom1|\n",
      "|  2|    Nikita| 27| 45800|               UP|   nom2|\n",
      "|  3|    Pritam| 24| 45720|Bangalore,Kolkata|   nom3|\n",
      "|  4|Prathamesh| 22|789651|    India,Kolkata|   nom4|\n",
      "|  5|      Roni| 21| 30000|             null|   nom5|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                .option(\"mode\", \"FAILFAST\")\\\n",
    "                    .load(\"/FileStore/tables/employee-1.csv\")\n",
    "\n",
    "df_employee.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14705069-f122-44d2-adae-8f1448a95870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType,StructType,StructField,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c85bce0-7db2-4a2c-8d3e-a86c66ee6f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_schema=StructType([\n",
    "    StructField(\"id\",IntegerType(), True),\n",
    "    StructField(\"name\",StringType(), True),\n",
    "    StructField(\"age\",IntegerType(), True),\n",
    "\tStructField(\"salary\",IntegerType(), False),\n",
    "\tStructField(\"address\",StringType(), True),\n",
    "\tStructField(\"_corrupt_record\",StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f98568d1-d3e5-4105-9da3-a0e541c7365f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+-----------------+-------------------------------------------+\n",
      "|id |name      |age|salary|address          |_corrupt_record                            |\n",
      "+---+----------+---+------+-----------------+-------------------------------------------+\n",
      "|1  |Manish    |26 |75000 |Bihar            |1,Manish,26,75000,Bihar,nom1               |\n",
      "|2  |Nikita    |27 |45800 |UP               |2,Nikita,27,45800,UP,nom2                  |\n",
      "|3  |Pritam    |24 |45720 |Bangalore,Kolkata|3,Pritam,24,45720,\"Bangalore,Kolkata\",nom3 |\n",
      "|4  |Prathamesh|22 |789651|India,Kolkata    |4,Prathamesh,22,789651,\"India,Kolkata\",nom4|\n",
      "|5  |Roni      |21 |30000 |null             |5,Roni,21,30000,,nom5                      |\n",
      "+---+----------+---+------+-----------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                .option(\"mode\", \"PERMISSIVE\")\\\n",
    "                    .schema(emp_schema)\\\n",
    "                    .load(\"/FileStore/tables/employee-1.csv\")\n",
    "\n",
    "df_employee.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ff67239-4f45-40c1-be3d-b74c519bfc2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Store Corrupted Record -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e617384-d906-414f-8d42-12297d518abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+-----------------+-------+\n",
      "| id|      name|age|salary|          address|nominee|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "|  1|    Manish| 26| 75000|            Bihar|   nom1|\n",
      "|  2|    Nikita| 27| 45800|               UP|   nom2|\n",
      "|  3|    Pritam| 24| 45720|Bangalore,Kolkata|   nom3|\n",
      "|  4|Prathamesh| 22|789651|    India,Kolkata|   nom4|\n",
      "|  5|      Roni| 21| 30000|             null|   nom5|\n",
      "+---+----------+---+------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee=spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\", \"true\")\\\n",
    "                    .option(\"badRecordsPath\",\"/FileStore/tables/bad_records\")\\\n",
    "                    .load(\"/FileStore/tables/employee-1.csv\")\n",
    "\n",
    "df_employee.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dae341a-acd1-45b6-b760-2bcba39112b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### bad records will store in json format. For this case no cottupted record thats why no directory created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d68c007-f444-404b-bdf1-42e50ed8de6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/employee-1.csv</td><td>employee-1.csv</td><td>208</td><td>1736482832000</td></tr><tr><td>dbfs:/FileStore/tables/employee.csv</td><td>employee.csv</td><td>247</td><td>1736482562000</td></tr><tr><td>dbfs:/FileStore/tables/flight-1.csv</td><td>flight-1.csv</td><td>7121</td><td>1736482562000</td></tr><tr><td>dbfs:/FileStore/tables/flight.csv</td><td>flight.csv</td><td>7121</td><td>1736400722000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/employee-1.csv",
         "employee-1.csv",
         208,
         1736482832000
        ],
        [
         "dbfs:/FileStore/tables/employee.csv",
         "employee.csv",
         247,
         1736482562000
        ],
        [
         "dbfs:/FileStore/tables/flight-1.csv",
         "flight-1.csv",
         7121,
         1736482562000
        ],
        [
         "dbfs:/FileStore/tables/flight.csv",
         "flight.csv",
         7121,
         1736400722000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls /FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70acaa05-358c-4969-a606-afcc4207c09c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3972844785739228,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DataBricks_Roni",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
